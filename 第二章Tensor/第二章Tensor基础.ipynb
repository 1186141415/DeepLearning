{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 2.1Tensor基础"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1数学含义"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensor对于pytorch实际上是array对于numpy，这个实际上是多维运算工具，不过是比numpy增加了各式各样的运算方法和函数。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2基本创建方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.9487, 0.0000, 0.3162, 0.0000],\n        [0.0000, 0.0000, 0.0000, 0.0000]])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(2, 4)  #创建张量\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.type())\n",
    "print(x.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "tensor一共包含八种数据类型：\n",
    "<img height=\"800\" src=\"2-1.jpeg\" width=\"1600\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ -2.0000e+00, -4.3323e-311,  7.9051e-323,   0.0000e+00],\n         [  0.0000e+00,   0.0000e+00,   0.0000e+00,  1.2599e-321],\n         [  0.0000e+00,   0.0000e+00,   0.0000e+00,   0.0000e+00]],\n\n        [[ 1.2599e-321,   0.0000e+00,   0.0000e+00,   0.0000e+00],\n         [  0.0000e+00,  1.2599e-321,   0.0000e+00,   0.0000e+00],\n         [  0.0000e+00,   0.0000e+00,  1.2599e-321,   0.0000e+00]]],\n       dtype=torch.float64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.DoubleTensor(2, 3, 4)  #两个3x4矩阵\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用python原生列表进行初始化\n",
    "list = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "torch.Tensor(list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5.)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Tensor和tensor大小写不一样\n",
    "'''\n",
    "#使用python索引方式获取Tensor中的元素值\n",
    "x = torch.Tensor([[2, 4, 5], [7, 6, 3]])\n",
    "x[0][2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2., 4., 9.],\n        [7., 6., 3.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用索引修改Tensor中的元素\n",
    "x[0][2] = 9\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3快速创建方法"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1.],\n        [1., 1., 1., 1.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6038, 0.3402, 0.6944, 0.5534],\n        [0.6187, 0.9854, 0.6149, 0.5955]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2, 4)  #创建[0,1)区间的随机数"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "print(torch.arange(1, 4))\n",
    "print(torch.arange(1, 4, 0.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "还有其他创建方法：\n",
    "<img alt=\"创建方法\" height=\"800\" src=\"2-2.jpeg\" width=\"1600\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4常用数学方法\n",
    "除了常见的加法，乘法和除法还有：\n",
    "<img alt=\"常用数学运算\" height=\"800\" src=\"2-3.png\" width=\"1600\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.Tensor([[1, 2, 3], [4, 5, 6]])\n",
    "b = torch.ones(2, 3)\n",
    "print(a)\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]])\n",
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]])\n",
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]])\n",
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(b.add(a))  #b本身的值不变\n",
    "print(torch.add(a, b))\n",
    "print(b.add_(a))  #覆盖加法\n",
    "print(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5182, 0.4103, 0.1761])\n",
      "tensor([2.5182, 2.4103, 2.1761])\n",
      "tensor([2.5182, 2.4103, 2.1761])\n",
      "tensor([2.5182, 2.4103, 2.1761])\n"
     ]
    }
   ],
   "source": [
    "#广播\n",
    "a = torch.rand(3)\n",
    "print(a)\n",
    "\n",
    "print(a + 2)\n",
    "\n",
    "print(torch.add(a, 2))\n",
    "\n",
    "print(a.add(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[5., 4., 3.],\n        [3., 2., 1.]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#abs方法\n",
    "torch.abs(torch.Tensor([[-5, -4, -3], [-3, -2, -1]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2000, 1.5000, 3.4000])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1., 2., 4.])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ceil向上取整数\n",
    "a = torch.Tensor([0.2, 1.5, 3.4])\n",
    "print(a)\n",
    "torch.ceil(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 2.7183,  7.3891, 20.0855])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exp取指数\n",
    "torch.exp(torch.Tensor([1, 2, 3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(3.)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(torch.Tensor([1, 2, 3]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5线性代数运算"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(20.)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dot向量与向量的内积运算\n",
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.Tensor([2, 3, 4])\n",
    "torch.dot(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 3., 4.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([1., 2., 3.])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([14., 20., 26.])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mv实现矩阵与向量的运算,m代表矩阵，v代表向量\n",
    "a = torch.Tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\n",
    "print(a)\n",
    "\n",
    "b = torch.Tensor([1, 2, 3])\n",
    "print(b)\n",
    "\n",
    "torch.mv(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [2., 3., 4.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([[2., 3., 4.],\n",
      "        [3., 4., 5.],\n",
      "        [4., 5., 6.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[20., 26., 32.],\n        [29., 38., 47.],\n        [38., 50., 62.]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mm将两个矩阵相乘\n",
    "a = torch.Tensor([[1, 2, 3], [2, 3, 4], [3, 4, 5]])\n",
    "print(a)\n",
    "\n",
    "b = torch.Tensor([[2, 3, 4], [3, 4, 5], [4, 5, 6]])\n",
    "print(b)\n",
    "\n",
    "torch.mm(a, b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "还有其他运算:\n",
    "<img alt=\"运算\" height=\"800\" src=\"2-4.jpeg\" width=\"1600\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6连接和切片"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2487, 0.9406],\n",
      "        [0.0747, 0.0851]])\n",
      "tensor([[0.7956, 0.2102],\n",
      "        [0.9757, 0.8366]])\n",
      "tensor([[0.2487, 0.9406],\n",
      "        [0.0747, 0.0851],\n",
      "        [0.7956, 0.2102],\n",
      "        [0.9757, 0.8366]])\n",
      "tensor([[0.2487, 0.9406, 0.7956, 0.2102],\n",
      "        [0.0747, 0.0851, 0.9757, 0.8366]])\n"
     ]
    }
   ],
   "source": [
    "#使用cat将多个Tensor沿莫纬度进行连接\n",
    "a = torch.rand(2, 2)\n",
    "print(a)\n",
    "\n",
    "b = torch.rand(2, 2)\n",
    "print(b)\n",
    "\n",
    "#在第0纬上进行连接\n",
    "print(torch.cat((a, b), 0))\n",
    "\n",
    "#在第2纬上进行连接\n",
    "print(torch.cat((a, b), 1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3213, 0.8758, 0.7084, 0.0452],\n",
      "        [0.5449, 0.9661, 0.5191, 0.6263]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "(tensor([[0.3213, 0.8758],\n         [0.5449, 0.9661]]),\n tensor([[0.7084, 0.0452],\n         [0.5191, 0.6263]]))"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用chunk进行切片，有三个参数，一个是切片对象，第二个是切片块数，第三个是切片纬度\n",
    "c = torch.rand(2, 4)\n",
    "print(c)\n",
    "\n",
    "torch.chunk(c, 2, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0209, 0.8066],\n",
      "        [0.0727, 0.1312]])\n",
      "tensor([[0.0209, 0.0727],\n",
      "        [0.8066, 0.1312]])\n"
     ]
    }
   ],
   "source": [
    "#使用t进行转置\n",
    "a = torch.rand(2, 2)\n",
    "print(a)\n",
    "\n",
    "print(torch.t(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "还有其他功能：\n",
    "<img alt=\"连接切片功能\" height=\"800\" src=\"2-5.jpeg\" width=\"1600\"/>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 7变形"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.2399, 0.8060, 0.0882, 0.1670],\n",
      "         [0.9213, 0.9991, 0.1535, 0.3507],\n",
      "         [0.9141, 0.5708, 0.1600, 0.7916]],\n",
      "\n",
      "        [[0.4118, 0.1386, 0.2066, 0.0916],\n",
      "         [0.7211, 0.1697, 0.4663, 0.6033],\n",
      "         [0.6194, 0.4225, 0.6824, 0.6231]]])\n",
      "tensor([[0.2399, 0.8060, 0.0882, 0.1670, 0.9213, 0.9991, 0.1535, 0.3507, 0.9141,\n",
      "         0.5708, 0.1600, 0.7916],\n",
      "        [0.4118, 0.1386, 0.2066, 0.0916, 0.7211, 0.1697, 0.4663, 0.6033, 0.6194,\n",
      "         0.4225, 0.6824, 0.6231]])\n",
      "tensor([[0.2399],\n",
      "        [0.8060],\n",
      "        [0.0882],\n",
      "        [0.1670],\n",
      "        [0.9213],\n",
      "        [0.9991],\n",
      "        [0.1535],\n",
      "        [0.3507],\n",
      "        [0.9141],\n",
      "        [0.5708],\n",
      "        [0.1600],\n",
      "        [0.7916],\n",
      "        [0.4118],\n",
      "        [0.1386],\n",
      "        [0.2066],\n",
      "        [0.0916],\n",
      "        [0.7211],\n",
      "        [0.1697],\n",
      "        [0.4663],\n",
      "        [0.6033],\n",
      "        [0.6194],\n",
      "        [0.4225],\n",
      "        [0.6824],\n",
      "        [0.6231]])\n",
      "torch.Size([24, 1])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 3, 4)\n",
    "print(x)\n",
    "\n",
    "y = x.view(2, 12)\n",
    "print(y)\n",
    "\n",
    "z = x.view(-1, 1)  #使用-1时会自动计算纬度的数目\n",
    "print(z)\n",
    "print(z.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 8使用cuda加速"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看机器是否支持cuda\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU计算时间:4.568583255999999\n",
      "未支持CUDA\n"
     ]
    }
   ],
   "source": [
    "#对比cpu和gpu运算时间\n",
    "#coding=utf-8\n",
    "from time import perf_counter\n",
    "\n",
    "x = torch.rand(1000, 10000)\n",
    "y = torch.rand(10000, 10000)\n",
    "\n",
    "#CPU\n",
    "start = perf_counter()\n",
    "x.mm(y)\n",
    "finish = perf_counter()\n",
    "time = finish - start\n",
    "print(\"CPU计算时间:%s\" % time)\n",
    "\n",
    "#GPU\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    start = perf_counter()\n",
    "    x.mm(y)\n",
    "    finish = perf_counter()\n",
    "    time_cuda = finish - start\n",
    "    print(\"GPU加速计算的时间:%s\" % time_cuda)\n",
    "    print(\"CPU计算时间是GPU加速计算时间的%s倍\" % str(time / time_cuda))\n",
    "\n",
    "else:\n",
    "    print(\"未支持CUDA\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2Autograd\n",
    "### 1微分示例\n",
    "pytorch的autograd功能可以自动求导\n",
    "### 2基本原理\n",
    "对Tensor变量设置参数即可，requires_grad设置后为True，grad参数会存储微分，grad_fn存储微分函数\n",
    "### 3前向传播"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2)\n",
    "x.requires_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1.], requires_grad=True)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad = True\n",
    "x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(x.grad_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([4., 4.], grad_fn=<MulBackward0>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 4 * x\n",
    "z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(5.6569, grad_fn=<CopyBackwards>)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = z.norm()\n",
    "y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4反向传播"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.8284, 2.8284])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward\n",
    "x.grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#只有末端的节点梯度才会被更新\n",
    "print(z.grad)\n",
    "print(y.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5非标量输出\n",
    "输出是非标量时，使用反向传播要增加一个与输出形状一样的ones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.],\n",
      "        [3.]], grad_fn=<MmBackward0>)\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.ones(2, 1)\n",
    "X = torch.Tensor([[2, 3], [1, 2]])\n",
    "X.requires_grad=True\n",
    "\n",
    "y=X.mm(z)\n",
    "print(y)\n",
    "\n",
    "y.backward(torch.ones(2,1))\n",
    "print(X.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}